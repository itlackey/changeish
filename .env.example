# Configuration examples for changeish

## Ollama Configuration
# Note: the Ollama CLI will use the CHANGEISH_MODEL variable or the CLI --model arg to determine which model to use.
### Basic setup for Ollama CLI
CHANGEISH_MODEL=qwen2.5-coder

## Remote OpenAI Compatible API Configuration
# Note: the CHANGEISH_API_MODEL variable or the CLI --model arg will determine which model to use

## OpenAI Configuration
### Basic setup for OpenAI
CHANGEISH_API_MODEL=gpt-4o-mini
CHANGEISH_API_URL=https://api.openai.com/v1/chat/completions
CHANGEISH_API_KEY=your_openai_api_key_here


## Azure OpenAI Configuration
### Using existing environment variables
# Assuming you have set the following environment variables in your system:
# AZURE_OPENAI_API_INSTANCE_NAME=<instance name>
# AZURE_OPENAI_API_KEY=<api key>
# AZURE_OPENAI_API_VERSION=<api version>
# AZURE_OPENAI_API_DEPLOYMENT_NAME=<deployment name>
# You can use them to define the changeish configuration. Uncomment the following lines:

## If your deployment name and model name are different, set the model name here or use the --model flag in the CLI
# CHANGEISH_API_MODEL=$AZURE_OPENAI_API_DEPLOYMENT_NAME

## Create the proper API URL for Azure OpenAI
# CHANGEISH_API_URL="https://$AZURE_OPENAI_API_INSTANCE_NAME.openai.azure.com/openai/deployments/$AZURE_OPENAI_API_DEPLOYMENT_NAME/chat/completions?api-version=$AZURE_OPENAI_API_VERSION"

## Use the Azure OpenAI API key for authentication
# CHANGEISH_API_KEY=$AZURE_OPENAI_API_KEY

### Alternative: Directly set Azure OpenAI Configuration

## Set this to the name of your Azure OpenAI model
# CHANGEISH_API_MODEL=<MODEL NAME>

## Create the proper API URL for Azure OpenAI
# CHANGEISH_API_URL="https://<INSTANCE NAME>.openai.azure.com/openai/deployments/<DEPLOYMENT NAME>/chat/completions?api-version=<API VERSION>"

## Use the Azure OpenAI API key for authentication
# CHANGEISH_API_KEY=<API KEY>